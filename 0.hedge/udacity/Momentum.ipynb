{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import quandl as ql\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas_datareader.data as web\n",
    "from datetime import datetime\n",
    "import dask as dd\n",
    "from dask import dataframe as ddf\n",
    "\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "start = datetime(2014, 1, 1)\n",
    "end = datetime(2018, 12, 11)\n",
    "\n",
    "key = 'YgkL6nxrm_SsUs7so2MM'\n",
    "\n",
    "\n",
    "#Momentum Strategy\n",
    "#1. Choose a universe of stocks, get daily prices\n",
    "#2. Resample Daily prices and extract month-end-prices, compute log returns month-end resampled daily prices\n",
    "#3. Rank by month-end returns selecting top n and bottom n\n",
    "#4. Compute long and short portfolio returns (assume equal dollar amount of investment)\n",
    "#5. Combine portfolio returns: Difference between short portfolio return and long portfolio return\n",
    "\n",
    "#Test this at the start of every month but I really think this is a stupid idea. \n",
    "#What is the optimal period to select? Maybe there are more meaningful temporal definitions\n",
    "#What is the optimal #number of assets to hold?\n",
    "#Should we compare against some moving average estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def days_to_weeks(open_prices, high_prices, low_prices, close_prices):\n",
    "    \"\"\"Converts daily OHLC prices to weekly OHLC prices.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    open_prices : DataFrame\n",
    "        Daily open prices for each ticker and date\n",
    "    high_prices : DataFrame\n",
    "        Daily high prices for each ticker and date\n",
    "    low_prices : DataFrame\n",
    "        Daily low prices for each ticker and date\n",
    "    close_prices : DataFrame\n",
    "        Daily close prices for each ticker and date\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    open_prices_weekly : DataFrame\n",
    "        Weekly open prices for each ticker and date\n",
    "    high_prices_weekly : DataFrame\n",
    "        Weekly high prices for each ticker and date\n",
    "    low_prices_weekly : DataFrame\n",
    "        Weekly low prices for each ticker and date\n",
    "    close_prices_weekly : DataFrame\n",
    "        Weekly close prices for each ticker and date\n",
    "    \"\"\"\n",
    "    \n",
    "    # TODO: Implement Function\n",
    "    \n",
    "    open_prices_weekly = open_prices.resample('10D').first()\n",
    "    high_prices_weekly = high_prices.resample('10D').max()\n",
    "    low_prices_weekly = low_prices.resample('10D').min()\n",
    "    close_prices_weekly = close_prices.resample('10D').last()\n",
    "    \n",
    "    return open_prices_weekly, high_prices_weekly, low_prices_weekly, close_prices_weekly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "company_list = pd.read_csv('/Users/justinsimcock/Downloads/companylist.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#thank you to Kaggle for making this available. \n",
    "hist = pd.read_csv('/Users/justinsimcock/Downloads/daily-historical-stock-prices-1970-2018/historical_stock_prices.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set date to datetime object from a string\n",
    "hist['date'] = pd.to_datetime(hist['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select the time period you want\n",
    "#right now I am only selecting from 2017\n",
    "post_2017_prices = hist.loc[hist.date >= '2017-01-01']\n",
    "post_2017_prices = post_2017_prices.set_index('date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5685"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(post_2017_prices.ticker.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'compute_log_returns' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-fbe90524831b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mweekly_close_ticker\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroupby_weekly_ticker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mweekly_returns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_log_returns\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweekly_close_ticker\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mweekly_lookahead\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_lookahead_returns\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweekly_close_ticker\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mperiod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mtop_weekly_n_long\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_top_n\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweekly_returns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'compute_log_returns' is not defined"
     ]
    }
   ],
   "source": [
    "#Create our time series that we'll use for analysis. \n",
    "#We can test different time windows and this will be the next step\n",
    "groupby_weekly_ticker = post_2017_prices.groupby('ticker').resample('W')\n",
    "weekly_close_ticker = groupby_weekly_ticker.close.last().dropna(axis=0)\n",
    "\n",
    "weekly_returns = compute_log_returns(weekly_close_ticker).unstack(level=0)\n",
    "weekly_lookahead = compute_lookahead_returns(weekly_close_ticker, period=1).unstack(level=0)\n",
    "top_weekly_n_long = get_top_n(weekly_returns, 50)\n",
    "top_weekly_n_short = get_top_n(-weekly_returns, 50)\n",
    "returns = portfolio_returns(top_weekly_n_long, top_weekly_n_short, weekly_lookahead, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for xarray workflow...this is next\n",
    "xr_weekly_close = weekly_close_ticker.to_xarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_weekly_n_short.iloc[0].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_lookahead_returns(prices,period):\n",
    "    '''\n",
    "    Compute lookahead returns for each ticker.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    prices : DataFrame\n",
    "        Prices for each ticker and date\n",
    "    \n",
    "    period: int\n",
    "        Periods to shift and compute lookahead\n",
    "    Returns\n",
    "    -------\n",
    "    returns : DataFrame\n",
    "        returns for each ticker and date\n",
    "    '''\n",
    "    \n",
    "    return prices - prices.shift(period)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_n(prev_returns, top_n):\n",
    "    \"\"\"\n",
    "    Select the top performing stocks\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    prev_returns : DataFrame\n",
    "        Previous shifted returns for each ticker and date\n",
    "    top_n : int\n",
    "        The number of top performing stocks to get\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    top_stocks : DataFrame\n",
    "        Top stocks for each ticker and date marked with a 1\n",
    "    \"\"\"\n",
    "    prev_returns_copy = prev_returns.copy()\n",
    "    cols = prev_returns_copy.columns\n",
    "    for idx, r in prev_returns_copy.iterrows():\n",
    "        n_largest = r.nlargest(top_n)\n",
    "\n",
    "        prev_returns_copy.loc[idx, cols[cols.isin(n_largest.index)]] = np.int(1)\n",
    "        prev_returns_copy.loc[idx, cols[~cols.isin(n_largest.index)]] = np.int(0)        \n",
    "    \n",
    "    return prev_returns_copy.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr_log_returns = compute_log_returns_xr(xr_weekly_close, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_list = []\n",
    "# for i in list_index:\n",
    "#     symbol = company_list.iloc[i]['Symbol']\n",
    "#     try:\n",
    "#         series = web.DataReader(symbol, 'iex', start, end)\n",
    "#     except Exception as e:\n",
    "#         print(e)\n",
    "#         continue\n",
    "\n",
    "#     df = pd.DataFrame.from_dict({'symbol': [symbol], 'start': [series.iloc[0].close], \n",
    "#                           'end': [series.iloc[-1].close], 'change': [series.iloc[-1].close - series.iloc[0].close]})\n",
    "                               \n",
    "#     df_list.append(df)\n",
    "                               \n",
    "\n",
    "# strat_df = pd.concat(df_list, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_positions(prices):\n",
    "    \"\"\"\n",
    "    Generate the following signals:\n",
    "     - Long 30 share of stock when the price is above 50 dollars\n",
    "     - Short 10 shares when it's below 20 dollars\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    prices : DataFrame\n",
    "        Prices for each ticker and date\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    final_positions : DataFrame\n",
    "        Final positions for each ticker and date\n",
    "    \"\"\"\n",
    "    # TODO: Implement Functions\n",
    "    \n",
    "    pos_long = 30 * (prices > 50).astype(np.int)\n",
    "    pos_short = -10 *(prices < 20).astype(np.int)\n",
    "    \n",
    "    return pos_long + pos_short"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_log_returns(prices):\n",
    "    \"\"\"\n",
    "    Compute log returns for each ticker.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    prices : DataFrame\n",
    "        Prices for each ticker and date\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    log_returns : DataFrame\n",
    "        Log returns for each ticker and date\n",
    "    \"\"\"    \n",
    "    return (np.log(prices) - np.log(prices.shift(1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shift_returns(returns, shift_n):\n",
    "    \"\"\"\n",
    "    Generate shifted returns\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    returns : DataFrame\n",
    "        Returns for each ticker and date\n",
    "    shift_n : int\n",
    "        Number of periods to move, can be positive or negative\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    shifted_returns : DataFrame\n",
    "        Shifted returns for each ticker and date\n",
    "    \"\"\"    \n",
    "    return returns.shift(shift_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_log_returns_xr(prices, shift_n):\n",
    "    \"\"\"\n",
    "    Compute log returns for each ticker.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    prices : xr.DataArray\n",
    "        Prices for each ticker and date\n",
    "    \n",
    "    shift_n: int\n",
    "        intervals over which to shift\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    log_returns : xr.DataArray\n",
    "        Log returns for each ticker and date\n",
    "    \"\"\"    \n",
    "    return (np.log(prices) - np.log(prices.shift(date=shift_n)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample_prices(close_prices, freq='M'):\n",
    "    \"\"\"\n",
    "    Resample close prices for each ticker at specified frequency.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    close_prices : DataFrame\n",
    "        Close prices for each ticker and date\n",
    "    freq : str\n",
    "        What frequency to sample at\n",
    "        For valid freq choices, see http://pandas.pydata.org/pandas-docs/stable/timeseries.html#offset-aliases\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    prices_resampled : DataFrame\n",
    "        Resampled prices for each ticker and date\n",
    "    \"\"\"\n",
    "    \n",
    "    return close_prices.resample(freq).last()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def portfolio_returns(df_long, df_short, lookahead_returns, n_stocks):\n",
    "    \"\"\"\n",
    "    Compute expected returns for the portfolio, assuming equal investment in each long/short stock.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df_long : DataFrame\n",
    "        Top stocks for each ticker and date marked with a 1\n",
    "    df_short : DataFrame\n",
    "        Bottom stocks for each ticker and date marked with a 1\n",
    "    lookahead_returns : DataFrame\n",
    "        Lookahead returns for each ticker and date\n",
    "    n_stocks: int\n",
    "        The number number of stocks chosen for each month\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    portfolio_returns : DataFrame\n",
    "        Expected portfolio returns for each ticker and date\n",
    "    \"\"\"\n",
    "    \n",
    "    return (lookahead_returns*df_long)/n_stocks -  (lookahead_returns*df_short)/n_stocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "def analyze_alpha(expected_portfolio_returns_by_date):\n",
    "    \"\"\"\n",
    "    Perform a t-test with the null hypothesis being that the expected mean return is zero.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    expected_portfolio_returns_by_date : Pandas Series\n",
    "        Expected portfolio returns for each date\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    t_value\n",
    "        T-statistic from t-test\n",
    "    p_value\n",
    "        Corresponding p-value\n",
    "    \"\"\"\n",
    "    t, p = stats.ttest_1samp(expected_portfolio_returns_by_date, 0.0)\n",
    "\n",
    "    return t, p/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create our time series that we'll use for analysis. \n",
    "#We can test different time windows and this will be the next step\n",
    "groupby_weekly_ticker = post_2017_prices.groupby('ticker').resample('W')\n",
    "weekly_close_ticker = groupby_weekly_ticker.close.last().dropna(axis=0)\n",
    "\n",
    "weekly_returns = compute_log_returns(weekly_close_ticker).unstack(level=0)\n",
    "weekly_lookahead = compute_lookahead_returns(weekly_close_ticker, period=1).unstack(level=0)\n",
    "top_weekly_n_long = get_top_n(weekly_returns, 50)\n",
    "top_weekly_n_short = get_top_n(-weekly_returns, 50)\n",
    "returns = portfolio_returns(top_weekly_n_long, top_weekly_n_short, weekly_lookahead, 100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
